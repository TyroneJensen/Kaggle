{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-17T11:40:36.322234Z","iopub.execute_input":"2022-11-17T11:40:36.322632Z","iopub.status.idle":"2022-11-17T11:40:36.351943Z","shell.execute_reply.started":"2022-11-17T11:40:36.322601Z","shell.execute_reply":"2022-11-17T11:40:36.350816Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/titactoe/tic-tac-toe.csv\n/kaggle/input/the-ultimate-halloween-candy-power-ranking/candy-data.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Basic Modeling in scikit-learn","metadata":{}},{"cell_type":"markdown","source":"### Regression models\n\nIn the candy dataset, the outcome is a continuous variable describing how often the candy was chosen over another candy in a series of 1-on-1 match-ups. To predict this value (the win-percentage), you will use a regression model.","metadata":{}},{"cell_type":"code","source":"# import data\ncandies = pd.read_csv('../input/the-ultimate-halloween-candy-power-ranking/candy-data.csv')\ncandies.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:36.353998Z","iopub.execute_input":"2022-11-17T11:40:36.354680Z","iopub.status.idle":"2022-11-17T11:40:36.403145Z","shell.execute_reply.started":"2022-11-17T11:40:36.354643Z","shell.execute_reply":"2022-11-17T11:40:36.402310Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"  competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n0      100 Grand          1       0        1               0       0   \n1   3 Musketeers          1       0        0               0       1   \n2       One dime          0       0        0               0       0   \n3    One quarter          0       0        0               0       0   \n4      Air Heads          0       1        0               0       0   \n\n   crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n0                 1     0    1         0         0.732         0.860   \n1                 0     0    1         0         0.604         0.511   \n2                 0     0    0         0         0.011         0.116   \n3                 0     0    0         0         0.011         0.511   \n4                 0     0    0         0         0.906         0.511   \n\n   winpercent  \n0   66.971725  \n1   67.602936  \n2   32.261086  \n3   46.116505  \n4   52.341465  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>competitorname</th>\n      <th>chocolate</th>\n      <th>fruity</th>\n      <th>caramel</th>\n      <th>peanutyalmondy</th>\n      <th>nougat</th>\n      <th>crispedricewafer</th>\n      <th>hard</th>\n      <th>bar</th>\n      <th>pluribus</th>\n      <th>sugarpercent</th>\n      <th>pricepercent</th>\n      <th>winpercent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100 Grand</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.732</td>\n      <td>0.860</td>\n      <td>66.971725</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3 Musketeers</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.604</td>\n      <td>0.511</td>\n      <td>67.602936</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>One dime</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.011</td>\n      <td>0.116</td>\n      <td>32.261086</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>One quarter</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.011</td>\n      <td>0.511</td>\n      <td>46.116505</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Air Heads</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.906</td>\n      <td>0.511</td>\n      <td>52.341465</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# create training data, labels and split into train and test sets\nfrom sklearn.model_selection import train_test_split\n\ncandies_X = candies.drop(['winpercent','competitorname'], axis=1)\ncandies_y = candies['winpercent']\n\nX_train, X_test, y_train, y_test = train_test_split(candies_X, candies_y, test_size=0.33, random_state=1111)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:36.404539Z","iopub.execute_input":"2022-11-17T11:40:36.405073Z","iopub.status.idle":"2022-11-17T11:40:37.008470Z","shell.execute_reply.started":"2022-11-17T11:40:36.405034Z","shell.execute_reply":"2022-11-17T11:40:37.006901Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Set parameters and fit a model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# instantiate model and set parameters\nrfr = RandomForestRegressor()\nrfr.n_estimators = 50\nrfr.max_depth = 10\nrfr.random_state = 1111\n\n# fit the model\nrfr.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.012782Z","iopub.execute_input":"2022-11-17T11:40:37.013663Z","iopub.status.idle":"2022-11-17T11:40:37.338632Z","shell.execute_reply.started":"2022-11-17T11:40:37.013619Z","shell.execute_reply":"2022-11-17T11:40:37.337582Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"RandomForestRegressor(max_depth=10, n_estimators=50, random_state=1111)"},"metadata":{}}]},{"cell_type":"markdown","source":"Updating parameters after the model is initialized is helpful when you need to update parameters later","metadata":{}},{"cell_type":"markdown","source":"#### Feature importances\nWhich variables had the biggest impact? You can check how important each variable was in the model by looping over the feature importance array using enumerate().","metadata":{}},{"cell_type":"code","source":"# Print how important each column is to the model\nfor i, item in enumerate(rfr.feature_importances_):\n      # Use i and item to print out the feature importance of each column\n    print(f\"{X_train.columns[i]}: {item.round(2)}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.339879Z","iopub.execute_input":"2022-11-17T11:40:37.340278Z","iopub.status.idle":"2022-11-17T11:40:37.353948Z","shell.execute_reply.started":"2022-11-17T11:40:37.340245Z","shell.execute_reply":"2022-11-17T11:40:37.352588Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"chocolate: 0.46\nfruity: 0.03\ncaramel: 0.01\npeanutyalmondy: 0.04\nnougat: 0.0\ncrispedricewafer: 0.01\nhard: 0.01\nbar: 0.02\npluribus: 0.02\nsugarpercent: 0.21\npricepercent: 0.17\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = rfr.predict(X_test)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.355763Z","iopub.execute_input":"2022-11-17T11:40:37.356258Z","iopub.status.idle":"2022-11-17T11:40:37.376085Z","shell.execute_reply.started":"2022-11-17T11:40:37.356213Z","shell.execute_reply":"2022-11-17T11:40:37.374497Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([51.7994252 , 74.24199692, 47.17086823, 40.77008747, 40.398765  ,\n       63.63481599, 69.686656  , 62.66550588, 39.58195998, 46.59214783,\n       54.18810166, 50.53322786, 65.74910948, 68.78238519, 45.73179682,\n       34.53633357, 46.04933601, 66.06938137, 46.39510062, 57.22623108,\n       38.99535844, 68.78238519, 75.87820292, 32.27741222, 54.05780172,\n       60.54649553, 55.1304664 , 55.22942462, 68.26581298])"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Accuracy metrics: regression models\nCommunicating modeling results can be difficult. However, most clients understand that on average, a predictive model was off by some number. This makes explaining the mean absolute error easy. For example, when predicting the number of wins for a basketball team, if you predict 42, and they end up with 40, you can easily explain that the error was two wins.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\n# Manually calculate the MAE\nn = len(y_pred)\nmae_one = sum(abs(y_test - y_pred)) / n\nprint('With a manual calculation, the error is {}'.format(mae_one))\n\n# Use scikit-learn to calculate the MAE\nmae_two = mean_absolute_error(y_test, y_pred)\nprint('Using scikit-learn, the error is {}'.format(mae_two))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.377946Z","iopub.execute_input":"2022-11-17T11:40:37.378337Z","iopub.status.idle":"2022-11-17T11:40:37.386835Z","shell.execute_reply.started":"2022-11-17T11:40:37.378304Z","shell.execute_reply":"2022-11-17T11:40:37.385568Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"With a manual calculation, the error is 10.114301059658457\nUsing scikit-learn, the error is 10.11430105965846\n","output_type":"stream"}]},{"cell_type":"markdown","source":"If you use the MAE, this accuracy metric does not reflect the bad predictions as much as if you use the MSE. Squaring the large errors from bad predictions will make the accuracy look worse.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nn = len(y_pred)\n# Finish the manual calculation of the MSE\nmse_one = sum((y_test - y_pred)**2) / n\nprint('With a manual calculation, the error is {}'.format(mse_one))\n\n# Use the scikit-learn function to calculate MSE\nmse_two = mean_squared_error(y_test, y_pred)\nprint('Using scikit-learn, the error is {}'.format(mse_two))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.388953Z","iopub.execute_input":"2022-11-17T11:40:37.389544Z","iopub.status.idle":"2022-11-17T11:40:37.402528Z","shell.execute_reply.started":"2022-11-17T11:40:37.389499Z","shell.execute_reply":"2022-11-17T11:40:37.401235Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"With a manual calculation, the error is 152.34455653729066\nUsing scikit-learn, the error is 152.34455653729066\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Classification models\nMethods .predict() and .predict_proba() using the tic_tac_toe dataset. The first method will give a prediction of whether Player One will win the game, and the second method will provide the probability of Player One winning. Use rfc as the random forest classification model.","metadata":{}},{"cell_type":"code","source":"tic_tac_toe = pd.read_csv('../input/titactoe/tic-tac-toe.csv')\ntic_tac_toe.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.404145Z","iopub.execute_input":"2022-11-17T11:40:37.404777Z","iopub.status.idle":"2022-11-17T11:40:37.438639Z","shell.execute_reply.started":"2022-11-17T11:40:37.404731Z","shell.execute_reply":"2022-11-17T11:40:37.437678Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"  Top-Left Top-Middle Top-Right Middle-Left Middle-Middle Middle-Right  \\\n0        x          x         x           x             o            o   \n1        x          x         x           x             o            o   \n2        x          x         x           x             o            o   \n3        x          x         x           x             o            o   \n4        x          x         x           x             o            o   \n\n  Bottom-Left Bottom-Middle Bottom-Right     Class  \n0           x             o            o  positive  \n1           o             x            o  positive  \n2           o             o            x  positive  \n3           o             b            b  positive  \n4           b             o            b  positive  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Top-Left</th>\n      <th>Top-Middle</th>\n      <th>Top-Right</th>\n      <th>Middle-Left</th>\n      <th>Middle-Middle</th>\n      <th>Middle-Right</th>\n      <th>Bottom-Left</th>\n      <th>Bottom-Middle</th>\n      <th>Bottom-Right</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>x</td>\n      <td>o</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>x</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>b</td>\n      <td>b</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>b</td>\n      <td>o</td>\n      <td>b</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tic_tac_toe.info()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.444226Z","iopub.execute_input":"2022-11-17T11:40:37.444624Z","iopub.status.idle":"2022-11-17T11:40:37.467231Z","shell.execute_reply.started":"2022-11-17T11:40:37.444591Z","shell.execute_reply":"2022-11-17T11:40:37.466255Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 958 entries, 0 to 957\nData columns (total 10 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   Top-Left       958 non-null    object\n 1   Top-Middle     958 non-null    object\n 2   Top-Right      958 non-null    object\n 3   Middle-Left    958 non-null    object\n 4   Middle-Middle  958 non-null    object\n 5   Middle-Right   958 non-null    object\n 6   Bottom-Left    958 non-null    object\n 7   Bottom-Middle  958 non-null    object\n 8   Bottom-Right   958 non-null    object\n 9   Class          958 non-null    object\ndtypes: object(10)\nmemory usage: 75.0+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\n# create training data, labels\ntic_tac_toe_X = tic_tac_toe.drop('Class', axis=1)\ntic_tac_toe_y = tic_tac_toe['Class']\n\n# encode categorical training data and labels\n# another method to perform same processing is pd.get_dummies (shown later)\nohe = OneHotEncoder()\nle = LabelEncoder()\n\ntic_tac_toe_enc_X = ohe.fit_transform(tic_tac_toe_X)\ntic_tac_toe_enc_y = le.fit_transform(tic_tac_toe_y)\n\n# split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(tic_tac_toe_enc_X, tic_tac_toe_enc_y, test_size=0.2, random_state=1111)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.469006Z","iopub.execute_input":"2022-11-17T11:40:37.469595Z","iopub.status.idle":"2022-11-17T11:40:37.492149Z","shell.execute_reply.started":"2022-11-17T11:40:37.469549Z","shell.execute_reply":"2022-11-17T11:40:37.490857Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# instantiate model and set parameters\nrfc = RandomForestClassifier()\nrfc.n_estimators = 50\nrfc.max_depth = 10\nrfc.random_state = 1111\n\n# fit the model\nrfc.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.494218Z","iopub.execute_input":"2022-11-17T11:40:37.494576Z","iopub.status.idle":"2022-11-17T11:40:37.641640Z","shell.execute_reply.started":"2022-11-17T11:40:37.494546Z","shell.execute_reply":"2022-11-17T11:40:37.640627Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(max_depth=10, n_estimators=50, random_state=1111)"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Classification predictions","metadata":{}},{"cell_type":"code","source":"# Create arrays of predictions\nclassification_predictions = rfc.predict(X_test)\nprobability_predictions = rfc.predict_proba(X_test)\n\n# Print out count of binary predictions\nprint(pd.Series(classification_predictions).value_counts())\n\n# Print the first value from probability_predictions\nprint('The first predicted probabilities are: {}'.format(probability_predictions[0]))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.643055Z","iopub.execute_input":"2022-11-17T11:40:37.643649Z","iopub.status.idle":"2022-11-17T11:40:37.672645Z","shell.execute_reply.started":"2022-11-17T11:40:37.643616Z","shell.execute_reply":"2022-11-17T11:40:37.671354Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"1    135\n0     57\ndtype: int64\nThe first predicted probabilities are: [0.16383333 0.83616667]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create predictions on X_test\npredictions = rfc.predict(X_test)\nprint(predictions[0:5])\n\n# Print model accuracy using score() and the testing data\nprint(rfc.score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.674263Z","iopub.execute_input":"2022-11-17T11:40:37.676360Z","iopub.status.idle":"2022-11-17T11:40:37.706219Z","shell.execute_reply.started":"2022-11-17T11:40:37.676318Z","shell.execute_reply":"2022-11-17T11:40:37.704813Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[1 1 1 0 1]\n0.984375\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Reusing model parameters","metadata":{}},{"cell_type":"code","source":"# Print the classification model\nprint(rfc)\n\n# Print the classification model's random state parameter\nprint('The random state is: {}'.format(rfc.random_state))\n\n# Print all parameters\nprint('Printing the parameters dictionary: {}'.format(rfc.get_params()))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.707853Z","iopub.execute_input":"2022-11-17T11:40:37.709334Z","iopub.status.idle":"2022-11-17T11:40:37.717839Z","shell.execute_reply.started":"2022-11-17T11:40:37.709284Z","shell.execute_reply":"2022-11-17T11:40:37.716236Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"RandomForestClassifier(max_depth=10, n_estimators=50, random_state=1111)\nThe random state is: 1111\nPrinting the parameters dictionary: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Classification metrics","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Create predictions\ntest_predictions = rfc.predict(X_test)\n\n# Create and print the confusion matrix\ncm = confusion_matrix(y_test, test_predictions)\nprint(cm)\n\n# Print the true positives (actual 1s that were predicted 1s)\nprint(\"The number of true positives is: {}\".format(cm[1, 1]))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.721480Z","iopub.execute_input":"2022-11-17T11:40:37.724395Z","iopub.status.idle":"2022-11-17T11:40:37.748052Z","shell.execute_reply.started":"2022-11-17T11:40:37.724342Z","shell.execute_reply":"2022-11-17T11:40:37.746269Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[[ 57   3]\n [  0 132]]\nThe number of true positives is: 132\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score\nprint(f\"Accuracy  : {accuracy_score(y_test, test_predictions )}\")\nprint(f\"Precision : {precision_score(y_test, test_predictions )}\")\nprint(f\"Recall    : {recall_score(y_test, test_predictions )}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.749557Z","iopub.execute_input":"2022-11-17T11:40:37.750035Z","iopub.status.idle":"2022-11-17T11:40:37.761390Z","shell.execute_reply.started":"2022-11-17T11:40:37.749968Z","shell.execute_reply":"2022-11-17T11:40:37.760276Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Accuracy  : 0.984375\nPrecision : 0.9777777777777777\nRecall    : 1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Validation Basics","metadata":{}},{"cell_type":"markdown","source":"### Creating train, test, and validation datasets","metadata":{}},{"cell_type":"markdown","source":"#### Create one holdout set ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Create dummy variables using pandas\ntic_tac_toe_X = pd.get_dummies(tic_tac_toe.iloc[:,0:9])\ntic_tac_toe_y = tic_tac_toe.iloc[:, 9]\n\n# Create training and testing datasets. Use 10% for the test set\nX_train, X_test, y_train, y_test = train_test_split(tic_tac_toe_X, tic_tac_toe_y, test_size=0.1, random_state=1111)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.762464Z","iopub.execute_input":"2022-11-17T11:40:37.762820Z","iopub.status.idle":"2022-11-17T11:40:37.784907Z","shell.execute_reply.started":"2022-11-17T11:40:37.762782Z","shell.execute_reply":"2022-11-17T11:40:37.783951Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"#### Create two holdout sets","metadata":{}},{"cell_type":"code","source":"# Create temporary training and final testing datasets\nX_temp, X_test, y_temp, y_test  = train_test_split(tic_tac_toe_X, tic_tac_toe_y, test_size=0.2, random_state=1111)\n\n# Create the final training and validation datasets\nX_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=1111)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.786084Z","iopub.execute_input":"2022-11-17T11:40:37.786526Z","iopub.status.idle":"2022-11-17T11:40:37.796903Z","shell.execute_reply.started":"2022-11-17T11:40:37.786485Z","shell.execute_reply":"2022-11-17T11:40:37.795707Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy metrics: regression models","metadata":{}},{"cell_type":"code","source":"# See above regression model metrics","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.798475Z","iopub.execute_input":"2022-11-17T11:40:37.799092Z","iopub.status.idle":"2022-11-17T11:40:37.805968Z","shell.execute_reply.started":"2022-11-17T11:40:37.799040Z","shell.execute_reply":"2022-11-17T11:40:37.804780Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Classification metrics","metadata":{}},{"cell_type":"code","source":"# See above classification model metrics","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.807419Z","iopub.execute_input":"2022-11-17T11:40:37.807782Z","iopub.status.idle":"2022-11-17T11:40:37.819803Z","shell.execute_reply.started":"2022-11-17T11:40:37.807749Z","shell.execute_reply":"2022-11-17T11:40:37.818347Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Bias-Variance trade-off","metadata":{}},{"cell_type":"markdown","source":"#### Error due to under/over-fitting\nUsing too many features (columns) in a random forest model can lead to overfitting. A feature represents which columns of the data are used in a decision tree. The parameter max_features limits the number of features available.","metadata":{}},{"cell_type":"code","source":"# Refresh data\nX_train, X_test, y_train, y_test = train_test_split(candies_X, candies_y, test_size=0.2, random_state=1111)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.822452Z","iopub.execute_input":"2022-11-17T11:40:37.823065Z","iopub.status.idle":"2022-11-17T11:40:37.833922Z","shell.execute_reply.started":"2022-11-17T11:40:37.823004Z","shell.execute_reply":"2022-11-17T11:40:37.832985Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"num_features = [2,4,11]\n\nfor num in num_features:\n    rfr = RandomForestRegressor(n_estimators=25,random_state=1111,max_features=num)\n    rfr.fit(X_train, y_train)\n    \n    train_mae = mean_absolute_error(y_train, rfr.predict(X_train))\n    test_mae = mean_absolute_error(y_test, rfr.predict(X_test))\n    \n    print(f'max_features={num}')\n    print(f'The training error is {train_mae.round(2)}')\n    print(f'The testing error is {test_mae.round(2)}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.835808Z","iopub.execute_input":"2022-11-17T11:40:37.836218Z","iopub.status.idle":"2022-11-17T11:40:37.983598Z","shell.execute_reply.started":"2022-11-17T11:40:37.836184Z","shell.execute_reply":"2022-11-17T11:40:37.982368Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"max_features=2\nThe training error is 3.9\nThe testing error is 9.15\n\nmax_features=4\nThe training error is 3.6\nThe testing error is 8.79\n\nmax_features=11\nThe training error is 3.59\nThe testing error is 10.0\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Am I underfitting?\nThe more trees you use, the longer your random forest model will take to run. However, if you don't use enough trees, you risk underfitting","metadata":{}},{"cell_type":"code","source":"# Refresh data\nX_train, X_test, y_train, y_test = train_test_split(tic_tac_toe_enc_X, tic_tac_toe_enc_y, test_size=0.2, random_state=1111)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.986433Z","iopub.execute_input":"2022-11-17T11:40:37.986897Z","iopub.status.idle":"2022-11-17T11:40:37.994471Z","shell.execute_reply.started":"2022-11-17T11:40:37.986852Z","shell.execute_reply":"2022-11-17T11:40:37.993370Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ntrees = [1, 2, 3, 4, 5, 10, 20, 50]\ntest_scores, train_scores = [], []\n\nfor i in trees:\n    rfc = RandomForestClassifier(n_estimators=i, random_state=1111)\n    rfc.fit(X_train, y_train)\n    \n    train_predictions = rfc.predict(X_train)\n    test_predictions = rfc.predict(X_test)\n    \n    train_scores.append(round(accuracy_score(y_train, train_predictions), 2))\n    test_scores.append(round(accuracy_score(y_test, test_predictions), 2))\n    \n# Print the train and test scores.\nprint(f\"The training scores were: {train_scores}\")\nprint(f\"The testing scores were: {test_scores}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:37.996103Z","iopub.execute_input":"2022-11-17T11:40:37.997277Z","iopub.status.idle":"2022-11-17T11:40:38.336848Z","shell.execute_reply.started":"2022-11-17T11:40:37.997240Z","shell.execute_reply":"2022-11-17T11:40:38.335544Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"The training scores were: [0.94, 0.93, 0.98, 0.97, 0.99, 1.0, 1.0, 1.0]\nThe testing scores were: [0.83, 0.79, 0.89, 0.91, 0.91, 0.93, 0.97, 0.98]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Notice that with only one tree, both the train and test scores are low. As you add more trees, both errors improve. Even at 50 trees, this still might not be enough. Every time you use more trees, you achieve higher accuracy. At some point though, more trees increase training time, but do not decrease testing error.","metadata":{}},{"cell_type":"markdown","source":"## Cross Validation\nHoldout sets are a great start to model validation. However, using a single train and test set if often not enough. Cross-validation is considered the gold standard when it comes to validating model performance and is almost always used when tuning model hyper-parameters","metadata":{}},{"cell_type":"markdown","source":"### The problems with holdout sets","metadata":{}},{"cell_type":"code","source":"# Create two different samples of 200 observations \nsample1 = tic_tac_toe.sample(200, random_state=1111)\nsample2 = tic_tac_toe.sample(200, random_state=1171)\n\n# Print the number of common observations \nprint(len([index for index in sample1.index if index in sample2.index]))\n\n# Print the number of observations in the Class column for both samples \nprint(sample1['Class'].value_counts())\nprint(sample2['Class'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:38.338711Z","iopub.execute_input":"2022-11-17T11:40:38.339272Z","iopub.status.idle":"2022-11-17T11:40:38.354564Z","shell.execute_reply.started":"2022-11-17T11:40:38.339230Z","shell.execute_reply":"2022-11-17T11:40:38.353104Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"40\npositive    134\nnegative     66\nName: Class, dtype: int64\npositive    123\nnegative     77\nName: Class, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Notice that there are a varying number of positive observations for both sample test sets. Sometimes creating a single test holdout sample is not enough to achieve the high levels of model validation you want. You need to use something more robust.","metadata":{}},{"cell_type":"markdown","source":"### Cross Validation","metadata":{}},{"cell_type":"markdown","source":"#### KFold","metadata":{}},{"cell_type":"code","source":"# Refresh data\nX_train, X_test, y_train, y_test = train_test_split(candies_X, candies_y, test_size=0.2, random_state=1111)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:38.356236Z","iopub.execute_input":"2022-11-17T11:40:38.356661Z","iopub.status.idle":"2022-11-17T11:40:38.371055Z","shell.execute_reply.started":"2022-11-17T11:40:38.356628Z","shell.execute_reply":"2022-11-17T11:40:38.369560Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\n# Use KFold\nkf = KFold(n_splits=5, shuffle=True, random_state=1111)\n\n# Create splits\nsplits = kf.split(candies_X)\n\n# Print the number of indices\nfor train_index, val_index in splits:\n    print(\"Number of training indices: %s\" % len(train_index))\n    print(\"Number of validation indices: %s\" % len(val_index))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:38.376786Z","iopub.execute_input":"2022-11-17T11:40:38.377189Z","iopub.status.idle":"2022-11-17T11:40:38.384858Z","shell.execute_reply.started":"2022-11-17T11:40:38.377153Z","shell.execute_reply":"2022-11-17T11:40:38.383960Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Number of training indices: 68\nNumber of validation indices: 17\nNumber of training indices: 68\nNumber of validation indices: 17\nNumber of training indices: 68\nNumber of validation indices: 17\nNumber of training indices: 68\nNumber of validation indices: 17\nNumber of training indices: 68\nNumber of validation indices: 17\n","output_type":"stream"}]},{"cell_type":"markdown","source":"KFold() is a great method for accessing individual indices when completing cross-validation. One drawback is needing a for loop to work through the indices though. In the next lesson, you will look at an automated method for cross-validation using sklearn.","metadata":{}},{"cell_type":"markdown","source":"#### sklearn's cross_val_score()","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error, make_scorer\n\nrfr = RandomForestRegressor(n_estimators=25, random_state=1111)\nmse = make_scorer(mean_squared_error)\n\n# Set up cross_val_score\ncv = cross_val_score(estimator=rfr, X=candies_X, y=candies_y, cv=10, scoring=mse)\n\n# Print the mean error\nprint(cv.mean())","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:38.386598Z","iopub.execute_input":"2022-11-17T11:40:38.387342Z","iopub.status.idle":"2022-11-17T11:40:38.809090Z","shell.execute_reply.started":"2022-11-17T11:40:38.387307Z","shell.execute_reply":"2022-11-17T11:40:38.807873Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"155.4061992697056\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You now have a baseline score to build on. If you decide to build additional models or try new techniques, you should try to get an error lower than 155.4. Lower errors indicate that your popularity predictions are improving.","metadata":{}},{"cell_type":"markdown","source":"### Leave-one-out-cross-validation (LOOCV)\nUsing 5-fold cross-validation will train on only 80% of the data at a time. The candy dataset only has 85 rows though, and leaving out 20% of the data could hinder our model. However, using leave-one-out-cross-validation allows us to make the most out of our limited dataset and will give you the best estimate for your favorite candy's popularity!","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, make_scorer\n\n# Create scorer\nmae_scorer = make_scorer(mean_absolute_error)\n\nrfr = RandomForestRegressor(n_estimators=15, random_state=1111)\n\n# Implement LOOCV\nscores = cross_val_score(rfr, X=candies_X, y=candies_y, cv=candies_X.shape[0], scoring=mae_scorer)\n\n# Print the mean and standard deviation\nprint(\"The mean of the errors is: %s.\" % np.mean(scores))\nprint(\"The standard deviation of the errors is: %s.\" % np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:38.810473Z","iopub.execute_input":"2022-11-17T11:40:38.810814Z","iopub.status.idle":"2022-11-17T11:40:41.085060Z","shell.execute_reply.started":"2022-11-17T11:40:38.810783Z","shell.execute_reply":"2022-11-17T11:40:41.083882Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"The mean of the errors is: 9.52044832324183.\nThe standard deviation of the errors is: 7.349020637882744.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Selecting the best model with Hyperparameter tuning","metadata":{}},{"cell_type":"markdown","source":"#### Creating Hyperparameters","metadata":{}},{"cell_type":"code","source":"# Review the parameters of rfr\nprint(rfr.get_params())\n\n# Maximum Depth\nmax_depth = [4, 8, 12]\n\n# Minimum samples for a split\nmin_samples_split = [2, 5, 10]\n\n# Max features \nmax_features = [4, 6, 8, 10]","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:40:41.087135Z","iopub.execute_input":"2022-11-17T11:40:41.087505Z","iopub.status.idle":"2022-11-17T11:40:41.094665Z","shell.execute_reply.started":"2022-11-17T11:40:41.087471Z","shell.execute_reply":"2022-11-17T11:40:41.093291Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 15, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Running a model using ranges","metadata":{}},{"cell_type":"code","source":"import random\n\n# Fill in rfr using your variables\nrfr = RandomForestRegressor(n_estimators=100, max_depth=random.choice(max_depth), min_samples_split=random.choice(min_samples_split), max_features=random.choice(max_features))\n\n# Print out the parameters\nprint(rfr.get_params())","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:48:09.068664Z","iopub.execute_input":"2022-11-17T11:48:09.069118Z","iopub.status.idle":"2022-11-17T11:48:09.076175Z","shell.execute_reply.started":"2022-11-17T11:48:09.069079Z","shell.execute_reply":"2022-11-17T11:48:09.075141Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 12, 'max_features': 6, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### RandomizedSearchCV","metadata":{}},{"cell_type":"markdown","source":"#### Preparing for RandomizedSearch","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import make_scorer, mean_squared_error\n\n# Finish the dictionary by adding the max_depth parameter\nparam_dist = {\"max_depth\": [2, 4, 6, 8],\n              \"max_features\": [2, 4, 6, 8, 10],\n              \"min_samples_split\": [2, 4, 8, 16]}\n\n# Create a random forest regression model\nrfr = RandomForestRegressor(n_estimators=10, random_state=1111)\n\n# Create a scorer to use (use the mean squared error)\nscorer = make_scorer(mean_squared_error)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:57:51.241376Z","iopub.execute_input":"2022-11-17T11:57:51.241777Z","iopub.status.idle":"2022-11-17T11:57:51.249707Z","shell.execute_reply.started":"2022-11-17T11:57:51.241745Z","shell.execute_reply":"2022-11-17T11:57:51.248084Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"To use RandomizedSearchCV(), you need a distribution dictionary, an estimator, and a scorer—once you've got these, you can run a random search to find the best parameters for your model.","metadata":{}},{"cell_type":"code","source":"# Import the method for random search\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Build a random search using param_dist, rfr, and scorer\nrandom_search = RandomizedSearchCV(estimator=rfr, param_distributions=param_dist, n_iter=10, cv=5, scoring=scorer)\n\nrandom_search.fit(candies_X, candies_y)\n\n\nprint(random_search.cv_results_)\n\nprint(random_search.cv_results_['mean_test_score'])\n\nprint(random_search.best_score_)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T12:31:28.315154Z","iopub.execute_input":"2022-11-17T12:31:28.315544Z","iopub.status.idle":"2022-11-17T12:31:29.303314Z","shell.execute_reply.started":"2022-11-17T12:31:28.315512Z","shell.execute_reply":"2022-11-17T12:31:29.301931Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"{'mean_fit_time': array([0.01615925, 0.01546402, 0.01534762, 0.0155334 , 0.01499014,\n       0.01498542, 0.01497331, 0.01540751, 0.01467724, 0.01463027]), 'std_fit_time': array([1.84429040e-03, 1.68079234e-03, 6.91780250e-04, 8.12662342e-04,\n       9.60586532e-05, 3.30557901e-04, 7.16297672e-04, 5.32460515e-04,\n       4.65305493e-04, 5.75068013e-04]), 'mean_score_time': array([0.0033257 , 0.00321732, 0.00327063, 0.00338383, 0.00340376,\n       0.00360098, 0.00339427, 0.00320673, 0.00320635, 0.0032094 ]), 'std_score_time': array([2.84736193e-04, 6.23535650e-05, 5.37715037e-05, 2.09387574e-04,\n       4.14366020e-04, 5.62553447e-04, 3.33057310e-04, 4.14250480e-05,\n       5.14362543e-05, 1.75948388e-05]), 'param_min_samples_split': masked_array(data=[2, 4, 8, 8, 8, 4, 16, 4, 4, 2],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False],\n       fill_value='?',\n            dtype=object), 'param_max_features': masked_array(data=[10, 4, 8, 6, 10, 4, 2, 10, 8, 2],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False],\n       fill_value='?',\n            dtype=object), 'param_max_depth': masked_array(data=[8, 2, 6, 8, 4, 4, 2, 8, 2, 2],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False],\n       fill_value='?',\n            dtype=object), 'params': [{'min_samples_split': 2, 'max_features': 10, 'max_depth': 8}, {'min_samples_split': 4, 'max_features': 4, 'max_depth': 2}, {'min_samples_split': 8, 'max_features': 8, 'max_depth': 6}, {'min_samples_split': 8, 'max_features': 6, 'max_depth': 8}, {'min_samples_split': 8, 'max_features': 10, 'max_depth': 4}, {'min_samples_split': 4, 'max_features': 4, 'max_depth': 4}, {'min_samples_split': 16, 'max_features': 2, 'max_depth': 2}, {'min_samples_split': 4, 'max_features': 10, 'max_depth': 8}, {'min_samples_split': 4, 'max_features': 8, 'max_depth': 2}, {'min_samples_split': 2, 'max_features': 2, 'max_depth': 2}], 'split0_test_score': array([158.72365634, 153.70911725, 197.95428021, 155.99576952,\n       148.96386008, 168.5945907 , 165.18739337, 153.97754266,\n       149.20611007, 155.10633986]), 'split1_test_score': array([ 92.28570517, 106.84333366, 100.68969354,  99.35399035,\n       101.25382732, 113.15780041,  93.60945002, 108.59427493,\n        80.02777704,  88.71089641]), 'split2_test_score': array([ 73.14447575,  84.64586021,  74.78483741,  63.33318226,\n        71.7686673 ,  80.43548332, 100.04864127,  80.50912291,\n        60.99560838,  93.23129474]), 'split3_test_score': array([244.58735548, 291.0623022 , 201.40205879, 236.78976729,\n       213.56444824, 253.16473888, 282.58320484, 229.78502083,\n       234.51372767, 271.05432275]), 'split4_test_score': array([152.32561482, 124.83978049, 142.32544094, 141.48768111,\n       151.90196172, 144.19216035, 144.11921694, 125.52715216,\n       142.60300727, 142.35615403]), 'mean_test_score': array([144.21336151, 152.22007876, 143.43126218, 139.3920781 ,\n       137.49055293, 151.90895473, 157.10958129, 139.6786227 ,\n       133.46924609, 150.09180156]), 'std_test_score': array([60.16404905, 73.01285502, 50.74203173, 58.5736939 , 48.49542156,\n       58.65288102, 68.2141457 , 50.972841  , 61.07287535, 65.90546278]), 'rank_test_score': array([ 5,  2,  6,  8,  9,  3,  1,  7, 10,  4], dtype=int32)}\n[144.21336151 152.22007876 143.43126218 139.3920781  137.49055293\n 151.90895473 157.10958129 139.6786227  133.46924609 150.09180156]\n157.10958128701108\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}