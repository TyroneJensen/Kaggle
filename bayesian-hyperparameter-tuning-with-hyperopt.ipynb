{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-18T13:38:59.018002Z","iopub.execute_input":"2023-01-18T13:38:59.018507Z","iopub.status.idle":"2023-01-18T13:38:59.041005Z","shell.execute_reply.started":"2023-01-18T13:38:59.018469Z","shell.execute_reply":"2023-01-18T13:38:59.039724Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"/kaggle/input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Bayesian Hyperparameter tuning with Hyperopt\n\nIn this example you will set up and run a Bayesian hyperparameter optimization process using the package Hyperopt. You will set up the domain (which is similar to setting up the grid for a grid search), then set up the objective function. Finally, you will run the optimizer over 20 iterations.\n\nYou will need to set up the domain using values:\n\n- max_depth using quniform distribution (between 2 and 10, increasing by 2)\n- learning_rate using uniform distribution (0.001 to 0.9)\n\nNote that for the purpose of this exercise, this process was reduced in data sample size and hyperopt & GBM iterations. If you are trying out this method by yourself on your own machine, try a larger search space, more trials, more cvs and a larger dataset size to really see this in action!","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndata = pd.read_csv('/kaggle/input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv')\n\nX = data.drop('default.payment.next.month', axis=1)\ny = data['default.payment.next.month']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-01-18T13:38:59.043254Z","iopub.execute_input":"2023-01-18T13:38:59.044300Z","iopub.status.idle":"2023-01-18T13:38:59.170338Z","shell.execute_reply.started":"2023-01-18T13:38:59.044255Z","shell.execute_reply":"2023-01-18T13:38:59.169013Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from hyperopt import hp, fmin, tpe\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2023-01-18T13:38:59.173840Z","iopub.execute_input":"2023-01-18T13:38:59.175004Z","iopub.status.idle":"2023-01-18T13:38:59.179881Z","shell.execute_reply.started":"2023-01-18T13:38:59.174967Z","shell.execute_reply":"2023-01-18T13:38:59.178510Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Set up space dictionary with specified hyperparameters\nspace = {'max_depth': hp.quniform('max_depth', 1, 60, 2),'learning_rate': hp.uniform('learning_rate', 0.001,2)}\n\n# Set up objective function\ndef objective(params):\n    params = {'max_depth': int(params['max_depth']),'learning_rate': params['learning_rate']}\n    gbm_clf = GradientBoostingClassifier(n_estimators=500, **params) \n    best_score = cross_val_score(gbm_clf, X_train, y_train, scoring='accuracy', cv=3, n_jobs=4).mean()\n    loss = 1 - best_score\n    return loss\n\n# Run the algorithm\nbest = fmin(fn=objective,space=space, max_evals=100, rstate=np.random.default_rng(42), algo=tpe.suggest)\nprint(best)","metadata":{"execution":{"iopub.status.busy":"2023-01-18T13:38:59.183274Z","iopub.execute_input":"2023-01-18T13:38:59.184016Z","iopub.status.idle":"2023-01-18T15:22:38.645759Z","shell.execute_reply.started":"2023-01-18T13:38:59.183972Z","shell.execute_reply":"2023-01-18T15:22:38.644593Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"100%|██████████| 100/100 [1:43:39<00:00, 62.19s/trial, best loss: 0.17935323383084578]\n{'learning_rate': 0.02718826730513205, 'max_depth': 2.0}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Excellent! You succesfully built your first Bayesian hyperparameter tuning algorithm. This will be a very powerful tool for your machine learning modeling in future. Bayesian hyperparameter tuning is a new and popular method so this first taster is a valuable thing to gain experience in. You are highly encouraged to extend this example on your own!","metadata":{}},{"cell_type":"markdown","source":"{'learning_rate': 0.038093061276450534, 'max_depth': 2.0}","metadata":{}},{"cell_type":"markdown","source":"100%|██████████| 20/20 [11:43<00:00, 35.16s/trial, best loss: 0.18422885572139303]\n\n{'learning_rate': 0.08347945438445452, 'max_depth': 4.0}","metadata":{}},{"cell_type":"markdown","source":"100%|██████████| 100/100 [1:43:39<00:00, 62.19s/trial, best loss: 0.17935323383084578]\n\n{'learning_rate': 0.02718826730513205, 'max_depth': 2.0}","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}